# üì± PhoneGuardAI: Smartphone Hack Detection & Analysis

> Unmasking hidden threats with intelligent machine learning.

-----

## üöÄ Overview

**GuardianAI** is a comprehensive machine learning project designed to assess the risk of a smartphone being hacked. It leverages advanced classification models (Random Forest and XGBoost) and synthetic, human-like data to predict the likelihood of a phone being compromised based on various symptoms. The project includes robust data generation, preprocessing, hyperparameter tuning, and in-depth analysis using SHAP values and various performance metrics.

-----

## ‚ú® Features

  * **Realistic Data Generation**: Creates a synthetic dataset simulating common phone symptoms (battery drain, overheating, unknown apps, data usage, unauthorized access, app crashes) and labels them as "Hacked" or "Safe" to train the models.
  * **Data Preprocessing**: Handles categorical feature encoding using `LabelEncoder` and addresses class imbalance with `SMOTE` (Synthetic Minority Over-sampling Technique) to ensure fair model training.
  * **Advanced Machine Learning Models**: Implements and fine-tunes:
      * **Random Forest Classifier**: An ensemble learning method for classification.
      * **XGBoost Classifier**: A powerful gradient boosting framework for high performance.
  * **Hyperparameter Tuning**: Utilizes `GridSearchCV` to optimize model parameters for the best possible performance (measured by F1-score).
  * **Comprehensive Evaluation**: Provides in-depth insights into model performance through:
      * Cross-validation scores to assess model generalization.
      * Confusion Matrices for clear understanding of true positives, true negatives, false positives, and false negatives.
      * ROC Curves and AUC scores to evaluate classifier performance across different thresholds.
      * Precision-Recall Curves for understanding model performance on imbalanced datasets.
      * Detailed Classification Reports (Precision, Recall, F1-score).
  * **Interactive User Input**: Allows users to input their phone's symptoms and receive an immediate hack risk assessment from both trained models.
  * **Explainable AI (XAI) with SHAP**: Uses SHAP (SHapley Additive exPlanations) values to explain individual model predictions, showing which features contribute most to the hack risk assessment.
  * **Insightful Visualizations**: Generates various plots for better understanding of data and model behavior, including feature importance, risk score distributions, and user-reported symptoms.

-----

## üíª How to Run Locally

To get GuardianAI up and running on your local machine, follow these steps:

### 1\. Clone the Repository

```bash
git clone <your-repository-url>
cd <your-project-directory> # e.g., cd GuardianAI
```

*(Replace `<your-repository-url>` with the actual URL of your Git repository and `<your-project-directory>` with your desired project folder name.)*

-----

### 2\. Install Dependencies

Ensure you have Python installed (Python 3.8+ recommended). Then, install the required libraries using pip:

```bash
pip install pandas numpy scikit-learn imbalanced-learn xgboost matplotlib seaborn shap
```

-----

### 3\. Execute the Script

Run the main Python script from your terminal:

```bash
python mlprojectfinal.py # Or whatever your main script name is
```

This will:

1.  Generate a synthetic dataset named `phone_hack_dataset_enhanced.csv`.
2.  Load and preprocess the data.
3.  Train and tune the RandomForest and XGBoost models.
4.  Perform cross-validation and print average F1-scores.
5.  **Prompt you to enter your phone's symptoms** for a real-time risk assessment.
6.  Display performance metrics and generate various plots (which will pop up in separate windows).

-----

## üì∏ Screenshots

Here are some examples of the visualizations and outputs you can expect when running the script:
![image](https://github.com/user-attachments/assets/38cce041-ee4e-4642-8840-3eb14be6a6b7)
![image](https://github.com/user-attachments/assets/ca20841a-9848-4c3e-9f4f-0b13f2aee8c3)

*(**Important:** Replace `path/to/your/rf_feature_importance.png`, etc., with the actual relative paths or URLs to your saved plot images within your repository. You will need to save the plots generated by the script as image files to link them here.)*

-----

## üìä Results and Performance

The script will output detailed performance metrics for both the Random Forest and XGBoost models, including:

  * **Optimal Threshold**: The determined optimal classification threshold for predicting "Hacked" based on F1-score.
  * **Risk Scores**: Predicted probabilities of being hacked for the user's input.
  * **Classification Reports**: Precision, Recall, and F1-score for each class ("Safe" and "Hacked") on the test set.

Example output:

```
‚úÖ Enhanced dataset saved as phone_hack_dataset_enhanced.csv
Best RF parameters: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 100}
Best XGBoost parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}
RF Cross-validation F1 scores: 0.96 (¬±0.00)
XGBoost Cross-validation F1 scores: 0.96 (¬±0.00)

üì± Phone Hack Risk Assessment Tool üì±

Please answer the following questions about your phone's behavior:

Battery Drain Percentage (e.g., 85): 85
Is the phone overheating? (Yes/No): No
Are there unknown apps installed? (Yes/No): Yes
Data usage level? (Low/Medium/High): High
Any unauthorized access detected? (Yes/No): Yes
Do apps crash frequently? (Yes/No): Yes

üîç Analysis Complete!
Optimal threshold based on F1: 0.5 with F1 score: 0.99
RF Model - Risk score: 99.41%, Prediction: üö®Your phone is likely HACKED!
XGBoost Model - Risk score: 99.98%, Prediction: üö®Your phone is likely HACKED!

Detailed Performance Metrics (RF):
              precision    recall  f1-score   support

        Safe       1.00      1.00      1.00       856
      Hacked       0.99      0.99      0.99       144

    accuracy                           1.00      1000
   macro avg       1.00      1.00      1.00      1000
weighted avg       1.00      1.00      1.00      1000

Detailed Performance Metrics (XGBoost):
              precision    recall  f1-score   support

        Safe       1.00      1.00      1.00       856
      Hacked       0.99      0.99      0.99       144

    accuracy                           1.00      1000
   macro avg       1.00      1.00      1.00      1000
weighted avg       1.00      1.00      1.00      1000
```

-----

## üõ† Tech Stack

  * **Python**: The core programming language.
  * **NumPy**: For numerical operations.
  * **Pandas**: For data manipulation and analysis.
  * **Scikit-learn**: For machine learning models, preprocessing (e.g., `LabelEncoder`), model selection (`GridSearchCV`, `train_test_split`), and evaluation metrics.
  * **Imbalanced-learn (imblearn)**: For handling class imbalance with `SMOTE`.
  * **XGBoost**: For the high-performance gradient boosting classifier.
  * **Matplotlib**: For creating static, interactive, and animated visualizations.
  * **Seaborn**: For statistical data visualization, enhancing plot aesthetics.
  * **SHAP**: For model explainability.

-----

## ü§ù Contributing

Contributions are welcome\! If you have suggestions for improvements, new features, or bug fixes, please feel free to:

1.  Fork the repository.
2.  Create a new branch (`git checkout -b feature/your-feature-name`).
3.  Make your changes and commit them (`git commit -m 'Add new feature'`).
4.  Push to the branch (`git push origin feature/your-feature-name`).
5.  Open a Pull Request.

-----

## üìÑ License

This project is open-sourced under the MIT License. See the `LICENSE` file for more details.

-----

## üí¨ Let's Connect

Made with ‚ù§Ô∏è by @harshadpy

"Stay vigilant, stay secure. GuardianAI has your back." üõ°Ô∏è
